# -*- coding: utf-8 -*-
"""Chabot_Api

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aDtnQHDTRgNZW_FIM-hl0KcNbMJeHiJR
"""

import os
import zipfile
from fastapi import FastAPI
from pydantic import BaseModel
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA

app = FastAPI()

PERSIST_DIR = "docs/chroma/"
ZIP_FILE = "chroma.zip"

if not os.path.exists(PERSIST_DIR):
    if os.path.exists(ZIP_FILE):
        with zipfile.ZipFile(ZIP_FILE, "r") as zip_ref:
            zip_ref.extractall("docs/")
        print("✅ Extracted chroma.zip successfully!")
    else:
        raise FileNotFoundError(f"❌ {ZIP_FILE} not found! Please upload the zip file.")

embedding = SentenceTransformerEmbeddings()
vectordb = Chroma(persist_directory=PERSIST_DIR, embedding_function=embedding)
llm = ChatOpenAI(
    openai_api_base="https://openrouter.ai/api/v1",
    openai_api_key="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",
    model="deepseek/deepseek-r1-distill-llama-70b:free"
)

retriever = vectordb.as_retriever()
qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)
class QuestionRequest(BaseModel):
    question: str
@app.post("/ask")
def ask_question(request: QuestionRequest):
    answer = qa_chain.run(request.question)
    return {"question": request.question, "answer": answer}